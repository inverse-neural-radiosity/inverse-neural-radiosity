{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitsuba as mi\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "import nerad.integrator\n",
    "from nerad.utils.sensor_utils import create_transforms\n",
    "from nerad.utils.json_utils import write_json\n",
    "from nerad.utils.image_utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_list(images, titles: list[str], figure_title: str):\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(18, 3))\n",
    "    for i in range(len(images)):\n",
    "        axs[i].imshow(mi.util.convert_to_bitmap(images[i]))\n",
    "        axs[i].axis('off')\n",
    "        if titles is not None:\n",
    "            axs[i].set_title(titles[i])\n",
    "    if figure_title is not None:\n",
    "        fig.suptitle(figure_title)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1024\n",
    "rr_depth = 1\n",
    "rr_prob = 1.0\n",
    "spp = 1\n",
    "\n",
    "integrator = mi.load_dict({\n",
    "    'type': 'mypath',\n",
    "    'config': {\n",
    "        'type': 'dict',\n",
    "        'hide_emitters': True,\n",
    "        'return_depth': True,\n",
    "        'max_depth': max_depth,\n",
    "        'rr_depth': rr_depth,\n",
    "        'rr_prob': rr_prob,\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albedos = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.97, 0.99]\n",
    "path_lengths = {}\n",
    "images = {}\n",
    "for alb in albedos:\n",
    "    scene = mi.load_file('/data/nerad/mitsuba3_scenes/cube_scene/scene.xml', albedo=alb)\n",
    "    img = mi.render(scene, integrator=integrator, spp=spp)\n",
    "\n",
    "    path_lengths[alb] = img[:, :, -1].torch().cpu().view(-1).numpy()\n",
    "    images[alb] = img[:, :, :3]\n",
    "\n",
    "plot_list([images[v] for v in albedos], [str(v) for v in albedos], 'vary albedo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_gt():\n",
    "    out_root = Path(\"/data/nerad/datasets/cube_scene\")\n",
    "    scene_root = Path(\"/data/nerad/mitsuba3_scenes/cube_scene\")\n",
    "    sensors = mi.load_file(str(scene_root / \"cameras.xml\")).sensors()\n",
    "    integrator = mi.load_dict({\n",
    "        'type': 'mypath',\n",
    "        'config': {\n",
    "            'type': 'dict',\n",
    "            'hide_emitters': True,\n",
    "            'return_depth': False,\n",
    "            'max_depth': 1024,\n",
    "            'rr_depth': 1,\n",
    "            'rr_prob': 1.0,\n",
    "        }})\n",
    "\n",
    "    transforms = create_transforms(str(scene_root / \"scene.xml\"), len(sensors))\n",
    "    for alb in albedos:\n",
    "        alb_folder = out_root / f\"albedo_{alb}\"\n",
    "        alb_folder.mkdir(parents=True, exist_ok=True)\n",
    "        write_json(alb_folder / \"transforms.json\", transforms)\n",
    "\n",
    "        print(f\"Render albedo = {alb}\")\n",
    "        scene = mi.load_file(str(scene_root / \"scene.xml\"), albedo=alb)\n",
    "        for i, sensor in enumerate(tqdm(sensors)):\n",
    "            img = mi.render(scene, integrator=integrator, spp=512, sensor=sensor)\n",
    "            save_image(alb_folder, f\"{i:03d}\", [\"png\", \"exr\"], img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Path Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [1, 25, 50, 75, 99, 99.9]\n",
    "path_length_data_by_albedo = {}  # albedo -> dict[str, value]\n",
    "path_length_data_keys = [\"Minimum\", \"Maximum\", \"Average\", *(f\"{p}%\" for p in percentiles)]\n",
    "\n",
    "for alb in albedos:\n",
    "    data = path_lengths[alb]\n",
    "    perc = np.percentile(data, percentiles)\n",
    "    path_length_data_by_albedo[alb] = {\n",
    "        \"Minimum\": np.min(data),\n",
    "        \"Maximum\": np.max(data),\n",
    "        \"Average\": np.mean(data),\n",
    "        **{\n",
    "            f\"{p}%\": perc[j] for j, p in enumerate(percentiles)\n",
    "        }\n",
    "    }\n",
    "\n",
    "tab = PrettyTable([\"Albedo\", *(str(alb) for alb in albedos)])\n",
    "for key in path_length_data_keys:\n",
    "    tab.add_row([\n",
    "        key, *(f\"{path_length_data_by_albedo[v][key]:.3f}\" for v in albedos)\n",
    "    ])\n",
    "tab.align = \"r\"\n",
    "print(f\"spp = {spp}\")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"1%\", \"50%\", \"99%\", \"99.9%\"]:\n",
    "    plt.plot(np.array(albedos), np.array([path_length_data_by_albedo[v][key] for v in albedos]), label = key)\n",
    "plt.legend()\n",
    "plt.xlabel('albedos')\n",
    "plt.ylabel('path length')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a47518a2585e1b8b0714511cf66ba0eea31c8b0bb8da2668b7d7c19e4398bee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
